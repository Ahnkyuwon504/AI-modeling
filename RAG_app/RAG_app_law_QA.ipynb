{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_community gradio openai chromadb tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "0WUkteirjU_I",
        "outputId": "262b91ce-d73c-4f75-dfb3-3efa56da8c53"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.2.0-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.0.30)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (3.9.5)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.6-py3-none-any.whl (28 kB)\n",
            "Collecting langchain<0.3.0,>=0.2.0 (from langchain_community)\n",
            "  Downloading langchain-0.2.0-py3-none-any.whl (973 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m973.7/973.7 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<0.3.0,>=0.2.0 (from langchain_community)\n",
            "  Downloading langchain_core-0.2.1-py3-none-any.whl (308 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m308.5/308.5 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langsmith<0.2.0,>=0.1.0 (from langchain_community)\n",
            "  Downloading langsmith-0.1.62-py3-none-any.whl (122 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.3/122.3 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (1.25.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (8.3.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading marshmallow-3.21.2-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain<0.3.0,>=0.2.0->langchain_community)\n",
            "  Downloading langchain_text_splitters-0.2.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.0->langchain_community) (2.7.1)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.3.0,>=0.2.0->langchain_community)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting packaging<24.0,>=23.2 (from langchain-core<0.3.0,>=0.2.0->langchain_community)\n",
            "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.0->langchain_community)\n",
            "  Downloading orjson-3.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2024.2.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (4.11.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.0.3)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.0->langchain_community)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.0->langchain_community) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.0->langchain_community) (2.18.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: packaging, orjson, mypy-extensions, jsonpointer, typing-inspect, marshmallow, jsonpatch, langsmith, dataclasses-json, langchain-core, langchain-text-splitters, langchain, langchain_community\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.0\n",
            "    Uninstalling packaging-24.0:\n",
            "      Successfully uninstalled packaging-24.0\n",
            "Successfully installed dataclasses-json-0.6.6 jsonpatch-1.33 jsonpointer-2.4 langchain-0.2.0 langchain-core-0.2.1 langchain-text-splitters-0.2.0 langchain_community-0.2.0 langsmith-0.1.62 marshmallow-3.21.2 mypy-extensions-1.0.0 orjson-3.10.3 packaging-23.2 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import TextLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_text_splitters.base import Language\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain_community.chat_models import ChatOpenAI\n",
        "from langchain.chains import RetrievalQA\n",
        "import gradio as gr\n",
        "import os\n",
        "import warnings\n",
        "import json\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "1wecW2URguNP"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ChromaEmbedding:\n",
        "    def __init__(self, directory, embedding):\n",
        "        \"\"\"\n",
        "        :param directory: 벡터 데이터베이스 폴더\n",
        "        :param embedding: 임베딩을 수행할 모델\n",
        "        \"\"\"\n",
        "        self.directory = directory\n",
        "        self.chromaDb = Chroma(persist_directory=self.directory, embedding_function=embedding)\n",
        "\n",
        "    def addJSONL(self, jsonl_file):\n",
        "        \"\"\"\n",
        "        지정된 JSONL 파일을 로드하여 임베딩을 수행한다.\n",
        "        :param jsonl_file: JSONL 파일의 경로\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        with open(jsonl_file, 'r', encoding='utf-8') as file:\n",
        "            lines = file.readlines()\n",
        "\n",
        "        # JSONL 파일을 로드하여 임베딩을 수행한다.\n",
        "        documents = []\n",
        "        for line in lines:\n",
        "            data = json.loads(line)\n",
        "            question = data.get(\"question\", \"\")\n",
        "            answer = data.get(\"answer\", \"\")\n",
        "            content = f\"Question: {question}\\nAnswer: {answer}\"\n",
        "            documents.append(content)\n",
        "\n",
        "        text_splitter = RecursiveCharacterTextSplitter(\n",
        "            chunk_size=900,\n",
        "            chunk_overlap=0,\n",
        "            length_function=len,\n",
        "        )\n",
        "\n",
        "        # 문자열을 지정된 크기의 청크로 분할한다.\n",
        "        docs = text_splitter.create_documents(documents)\n",
        "\n",
        "        # 분할된 청크를 임베딩 데이터베이스에 저장한다.\n",
        "        self.chromaDb.add_documents(docs)\n",
        "        self.chromaDb.persist()"
      ],
      "metadata": {
        "id": "7opO4kW4gx5o"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 벡터 데이터베이스 폴더\n",
        "INDEX = \"/content/drive/MyDrive/AI-modeling/law_RAG app/app_QA_index\"\n",
        "\n",
        "def buildIndex():\n",
        "    \"\"\"\n",
        "    OpenAI 임베딩 모델을 이용하여 MARKDOWN 파일을 임베딩한다.\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    chroma = ChromaEmbedding(INDEX, OpenAIEmbeddings())\n",
        "    chroma.addJSONL(\"/content/drive/MyDrive/AI-modeling/law_RAG app/data/law_qa_sample.jsonl\")\n",
        "    print(\"임베딩 완료!\")"
      ],
      "metadata": {
        "id": "S34snIaKguZV"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "m77XwfZRgi05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "collapsed": true,
        "outputId": "636ea64c-3ae1-4a5e-8a0b-4e62cb7fd403"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "임베딩 완료!\n",
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://e4c63cdb22598f2652.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://e4c63cdb22598f2652.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "def runApplication():\n",
        "    \"\"\"\n",
        "    RAG 어플리케이션을 실행한다.\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    chroma = ChromaEmbedding(INDEX, OpenAIEmbeddings())\n",
        "    retriever = chroma.chromaDb.as_retriever(\n",
        "        search_type=\"similarity\",\n",
        "        search_kwargs={\n",
        "            'k': 2,  # 리턴 문서 수\n",
        "        }\n",
        "    )\n",
        "\n",
        "    # QA\n",
        "    qa_interface = RetrievalQA.from_chain_type(llm=ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0),\n",
        "                                               chain_type=\"stuff\",\n",
        "                                               retriever=retriever,\n",
        "                                               chain_type_kwargs={\n",
        "                                                   \"verbose\": True,\n",
        "                                               },\n",
        "                                               return_source_documents=True)\n",
        "\n",
        "    # 웹 화면을 구성한다.\n",
        "    with gr.Blocks() as rag_tester:\n",
        "        gr.HTML(\"<h2>법률 사례기반 챗봇</h2>\")\n",
        "        with gr.Row():\n",
        "            with gr.Column(scale=1):\n",
        "                query = gr.Textbox(label=\"질문\", value=\"법률 관련 질문을 입력하세요.\", lines=3)\n",
        "                with gr.Row():\n",
        "                    clear = gr.Button(\"Clear\")\n",
        "                    submit = gr.Button(\"Submit\", variant=\"primary\")\n",
        "            with gr.Column(scale=1):\n",
        "                with gr.Tab(\"답변\"):\n",
        "                    result = gr.Textbox(label=\"\", lines=6)\n",
        "                with gr.Tab(\"검색 문서\"):\n",
        "                    mkdown = gr.Markdown()\n",
        "\n",
        "        def submitHandler(input_text):\n",
        "            qa_result = qa_interface(input_text)\n",
        "\n",
        "            result = qa_result[\"result\"]\n",
        "            md_text = \"\"\n",
        "            for ix, doc in enumerate(qa_result['source_documents']):\n",
        "                md_text += f\"## 검색문서 {ix+1}\\n```\\n{doc.page_content}\\n```\\n\\n\"\n",
        "\n",
        "            return result, md_text\n",
        "\n",
        "        def clearHandler():\n",
        "            return \"\", \"\", \"\"\n",
        "\n",
        "        submit.click(submitHandler, inputs=[query], outputs=[result, mkdown])\n",
        "        clear.click(clearHandler, outputs=[query, result, mkdown])\n",
        "\n",
        "    rag_tester.launch()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # 임베딩 폴더가 없는 경우 임베딩을 수행한다.\n",
        "    # if not os.path.isdir(INDEX):\n",
        "        buildIndex()\n",
        "        runApplication()\n",
        "    # else:\n",
        "    #     runApplication()"
      ]
    }
  ]
}
