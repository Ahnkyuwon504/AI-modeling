{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPcBDLy9iNF8vtANnvEkLb4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ahnkyuwon504/AI-modeling/blob/main/papers_code/torch_feed_forward_nn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. 라이브러리 설치"
      ],
      "metadata": {
        "id": "aFrnqKZdtjkF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "EZyPlUnOtd8v"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from torch.utils.data import DataLoader, TensorDataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. 데이터 로드/전처리"
      ],
      "metadata": {
        "id": "q7ikidfztkh1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1. 데이터 로드"
      ],
      "metadata": {
        "id": "CdbcHvZit_KI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "8u3VzD8ttkh1"
      },
      "outputs": [],
      "source": [
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZUh8buSxSwK",
        "outputId": "130f61f0-5ddd-4234-f331-180ec4863564"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((120, 4), (120,), (30, 4), (30,))"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train[:10], y_train[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJUGiLTXuLvJ",
        "outputId": "cb68a1f3-ee42-4477-a2d4-69c1dc810f7f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[4.6 3.6 1.  0.2]\n",
            " [5.7 4.4 1.5 0.4]\n",
            " [6.7 3.1 4.4 1.4]\n",
            " [4.8 3.4 1.6 0.2]\n",
            " [4.4 3.2 1.3 0.2]\n",
            " [6.3 2.5 5.  1.9]\n",
            " [6.4 3.2 4.5 1.5]\n",
            " [5.2 3.5 1.5 0.2]\n",
            " [5.  3.6 1.4 0.2]\n",
            " [5.2 4.1 1.5 0.1]] [0 0 1 0 0 2 1 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2. 스케일링/분할"
      ],
      "metadata": {
        "id": "CTXY7mbYt-nh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "# Create DataLoader\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)"
      ],
      "metadata": {
        "id": "vLbrExKGt76o"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. 모델링"
      ],
      "metadata": {
        "id": "4-h3ES1Dtk7t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1. 모델 정의"
      ],
      "metadata": {
        "id": "XM4_q-bqu3uh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- `첫 번째 선형 계층 fully connected layer` iris데이터의 4차원 특성 -> 50차원\n",
        "- `두 번째 비선형 계층` ReLU 활성화함수로 50차원 -> 50차원\n",
        "- `세 번째 선형 계층 fully connected layer` 50차원 -> iris데이터의 3개의 클래스\n",
        "- `네 번째 비선형 계층` Softmax 활성화함수로 3개의 클래스에 대한 확률 계산"
      ],
      "metadata": {
        "id": "64zmiSQLvnkp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "HFNvrcJltk7u"
      },
      "outputs": [],
      "source": [
        "class FeedForwardNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(FeedForwardNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(4, 50)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(50, 3)\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.fc1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.fc2(out)\n",
        "        out = self.softmax(out)\n",
        "        return out\n",
        "\n",
        "model = FeedForwardNN()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2. 손실함수/최적화함수"
      ],
      "metadata": {
        "id": "3TtYYg3gtlLK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- `CrossEntropyLoss` 다중 클래스 분류 문제에서 자주 사용되는 손실함수\n",
        "- `Adam(Adaptive Moment Estimation)`은 스토캐스틱 경사 하강법 (SGD) 기반의 최적화 알고리즘 , learning rate는 하이퍼 파라미터(학습률)"
      ],
      "metadata": {
        "id": "mtTopbwNwdwu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "vQ7XPqdrtlLK"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. 학습"
      ],
      "metadata": {
        "id": "RILBeZ0ftlkE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 전체 데이터셋을 10번 반복\n",
        "- `model.train()` 모델을 학습모드로 설정\n",
        "- 현 에폭의 총 손실을 저장할 변수 초기화\n",
        "- train_loader을 통해 미니배치 단위로 학습데이터 순회"
      ],
      "metadata": {
        "id": "mUiXIGRgw72H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- `optimizer.zero_grad()` 이전 단계에서 계산된 그래디언트 초기화\n",
        "- `outputs = model(inputs)` 모델에 입력 데이터 통과\n",
        "- `loss = criterion(outputs, labels)` 예측값과 실제 레이블 간의 손실 계산\n",
        "- `loss.backward()` 역전파(backpropagation)를 통해 손실의 그래디언트 계산\n",
        "- `optimizer.step()` 옵티마이저를 사용하여 모델의 파라미터를 업데이트\n",
        "- `running_loss` 현재 미니배치의 손실 값을 누적"
      ],
      "metadata": {
        "id": "2A1RiiNqxkOR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJSZw5XUtlkE",
        "outputId": "6e7a8d9d-cc5d-4ae5-dae7-2691c1d227b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.8427\n",
            "Epoch [2/10], Loss: 0.8256\n",
            "Epoch [3/10], Loss: 0.8107\n",
            "Epoch [4/10], Loss: 0.8023\n",
            "Epoch [5/10], Loss: 0.7984\n",
            "Epoch [6/10], Loss: 0.7819\n",
            "Epoch [7/10], Loss: 0.7825\n",
            "Epoch [8/10], Loss: 0.7731\n",
            "Epoch [9/10], Loss: 0.7636\n",
            "Epoch [10/10], Loss: 0.7597\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. 평가"
      ],
      "metadata": {
        "id": "JKW-_2VDvACd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- `eval()` 모델을 평가모드로 전환\n",
        "- `test_loader`에서 미니배치 단위로 데이터 로드\n",
        "- `outputs = model(inputs)` 모델에 입력 데이터를 통과시켜 예측값을 얻음\n",
        "- `_, predicted = torch.max(outputs.data, 1)` 출력 값에서 가장 높은 확률을 가진 클래스의 인덱스를 예측값으로 선택. outputs.data는 모델의 출력 텐서입니다.\n",
        "dim=1은 클래스 차원입니다. 각 샘플에 대해 최대값의 인덱스를 찾습니다.\n",
        "_는 최대값 자체를 무시한다는 의미, predicted는 최대값의 인덱스를 받습니다. 인덱스는 예측된 클래스 레이블을 나타냅니다.\n",
        "- `total += labels.size(0)` 총 샘플 수를 누적\n",
        "- `correct += (predicted == labels).sum().item()` 정확하게 예측한 샘플 수를 누적합니다."
      ],
      "metadata": {
        "id": "zxJhoW7EydVS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-Tmmy8hvACd",
        "outputId": "4cff6da4-de75-4cd0-b782-da349fba7aa3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the model on the test set: 90.00%\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy of the model on the test set: {100 * correct / total:.2f}%')"
      ]
    }
  ]
}