{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO9d+dJTt3ZnEebgFkQ4HcA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ahnkyuwon504/AI-modeling/blob/main/papers_code/torch_knowledge_distillation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Import Modules"
      ],
      "metadata": {
        "id": "jf_Izxk7StMu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import time"
      ],
      "metadata": {
        "id": "eBi7oF4WStfe"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. DataSets"
      ],
      "metadata": {
        "id": "xIsLJcJIXMoG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "MXxE6aB7XMvK",
        "outputId": "40cbd096-e8e3-4977-cdf6-87054498e184"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 11732119.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 351747.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 3239609.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 4384471.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_loader.dataset.data.shape, test_loader.dataset.data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCW6BTC_boBl",
        "outputId": "8d33f2bf-e257-40c7-a99f-c1e956d157cf"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([60000, 28, 28]) torch.Size([10000, 28, 28])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Teacher/Student class Modeling"
      ],
      "metadata": {
        "id": "l93IxcNUSumT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- forward: `PyTorch의 nn.Module 클래스`에서 상속받은 함수로, 반드시 정의해야 하는 함수\n",
        "- 입력 데이터 X는 [batch_size, channels, height, width]\n",
        "- 따라서 x.size(0)는 batch_size=64개의 이미지\n",
        "- 입력 데이터 X를 1차원 벡터로 변환해 fully connected 레이어에 입력으로 사용"
      ],
      "metadata": {
        "id": "EjtA1pHuUsVY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TeacherModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(TeacherModel, self).__init__()\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(28*28, 400),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(400, 100),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(100, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fc(x.view(x.size(0), -1))\n",
        "\n",
        "class StudentModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(StudentModel, self).__init__()\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(28*28, 100),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(100, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fc(x.view(x.size(0), -1))"
      ],
      "metadata": {
        "id": "yEigjfKOSumU"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. 손실함수/옵티마이저"
      ],
      "metadata": {
        "id": "10bsXUx3TuRO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "optimizer = optim.Adam(teacher_model.parameters(), lr=0.005)\n",
        "student_model의 파라미터를 옵티마이저에 지정해서 꽤나 뻘짓 했다."
      ],
      "metadata": {
        "id": "52se4oSmajBa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 초기화\n",
        "teacher_model = TeacherModel()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(teacher_model.parameters(), lr=0.005)"
      ],
      "metadata": {
        "id": "dWs3KfkSTuRO"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. 학습(Teacher)"
      ],
      "metadata": {
        "id": "zc0X_H01Tufv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 5\n",
        "teacher_start_time = time.time()  # 평가 시작 시간 기록\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    teacher_model.train()  # 모델을 학습 모드로 전환\n",
        "    running_loss = 0.0\n",
        "    start_time = time.time()  # 평가 시작 시간 기록\n",
        "\n",
        "    for images, labels in train_loader:  # 데이터로더에서 배치를 가져옴\n",
        "        outputs = teacher_model(images)  # 모델을 통해 예측값 생성\n",
        "        loss = criterion(outputs, labels)  # 예측값과 실제 정답을 비교하여 손실 계산\n",
        "\n",
        "        optimizer.zero_grad()  # 이전 배치의 그래디언트를 초기화\n",
        "        loss.backward()  # 손실에 대한 그래디언트를 계산 (역전파)\n",
        "        optimizer.step()  # 계산된 그래디언트를 사용하여 모델 파라미터 업데이트\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}')\n",
        "\n",
        "teacher_end_time = time.time()  # 평가 시작 시간 기록\n",
        "teacher_learning_time = teacher_end_time - teacher_start_time  # 소요 시간 계산\n",
        "print(f'Learning Time: {teacher_learning_time:.4f} seconds')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMStWYESTufw",
        "outputId": "7d4bd52b-fd2b-451b-a320-a16eb5ab3962"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Loss: 0.3454\n",
            "Epoch [2/5], Loss: 0.1805\n",
            "Epoch [3/5], Loss: 0.1563\n",
            "Epoch [4/5], Loss: 0.1354\n",
            "Epoch [5/5], Loss: 0.1309\n",
            "Learning Time: 94.4465 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> 여기까지는 일반적인 심층신경망 학습과 동일"
      ],
      "metadata": {
        "id": "r1w8O43IXott"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Soft Targets 추출"
      ],
      "metadata": {
        "id": "oDzdJQTPSus5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "eval()\n",
        "- Dropout 및 Batch Normalization과 같은 레이어가 학습 시와 다르게 동작하도록 설정\n",
        "- 학습 모드에서는 Dropout이 활성화되어 일부 뉴런을 무작위로 꺼버리지만, 평가 모드에서는 모든 뉴런이 활성화\n",
        "\n",
        "torch.no_grad()\n",
        "- 그래디언트 계산 비활성화\n",
        "- 그래디언트가 계산되지 않으므로 메모리 사용량이 줄고 속도 향상\n",
        "- 모델 평가/예측 시에 주로 사용"
      ],
      "metadata": {
        "id": "iy8NPVLTZSwl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_soft_targets(model, dataloader):\n",
        "    model.eval()  # 모델을 평가 모드로 전환\n",
        "    soft_targets = []  # 소프트 타겟을 저장할 리스트 초기화\n",
        "    with torch.no_grad():  # 그래디언트 계산을 비활성화 (메모리 절약 및 속도 향상)\n",
        "        for images, _ in dataloader:  # 데이터로더에서 배치를 반복적으로 가져옴\n",
        "            outputs = model(images)  # 모델을 통해 예측값 생성\n",
        "            soft_targets.append(outputs)  # 예측값을 소프트 타겟 리스트에 추가\n",
        "    return torch.cat(soft_targets)  # 모든 배치의 예측값을 하나의 텐서로 결합하여 반환\n",
        "\n",
        "soft_targets = get_soft_targets(teacher_model, train_loader)"
      ],
      "metadata": {
        "id": "AAN4MKVASus5"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. 학습(Student)"
      ],
      "metadata": {
        "id": "zsDGnoOrSu2Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hard Loss\n",
        "- Student 모델의 출력값과 실제 레이블 간의 손실\n",
        "\n",
        "Soft Loss\n",
        "- Student 모델의 출력값과 Teacher 모델의 soft targets 간의 손실을 계산\n",
        "- KL Divergence 손실을 사용하여 두 확률 분포 간의 차이를 측정\n",
        "\n",
        "Temperature\n",
        "- Temperature는 Softmax 함수의 출력을 부드럽게 만드는 역할\n",
        "- T가 높을수록 확률 분포가 더 부드러워지고,이는 Teacher 모델의 soft targets를 부드럽게 만들어 Student 모델이 더 잘 학습할 수 있도록 합니다.\n",
        "\n",
        "Alpha\n",
        "- Hard loss와 Soft loss 간의 가중치를 조절하는 하이퍼파라미터\n",
        "- Alpha가 0에 가까울수록 Soft loss가 더 많이 반영되고, 1에 가까울수록 Hard loss가 더 많이 반영.\n",
        "\n",
        "nn.KLDivLoss()\n",
        "- 두 확률 분포 간의 차이를 계산하는 손실 함수\n",
        "\n",
        "KL Divergence(Kullback-Leibler Divergence)\n",
        "- 두 확률 분포 P와 Q 간의 차이를 측정하는 비대칭적인 측도\n"
      ],
      "metadata": {
        "id": "F61j9pJsSu81"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "student_model = StudentModel()\n",
        "optimizer = optim.Adam(student_model.parameters(), lr=0.005)\n",
        "\n",
        "# Student Model 학습\n",
        "def distillation_loss(outputs, targets, soft_targets, T, alpha):\n",
        "    hard_loss = criterion(outputs, targets)\n",
        "    soft_loss = nn.KLDivLoss()(nn.functional.log_softmax(outputs/T, dim=1), nn.functional.softmax(soft_targets/T, dim=1))\n",
        "    return alpha * hard_loss + (1 - alpha) * soft_loss\n",
        "\n",
        "alpha = 0.5\n",
        "T = 2.0\n",
        "\n",
        "student_start_time = time.time()  # 평가 시작 시간 기록\n",
        "\n",
        "student_model.train()\n",
        "for epoch in range(5):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        outputs = student_model(images)\n",
        "        loss = distillation_loss(outputs, labels, soft_targets[i*64:(i+1)*64], T, alpha)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/5], Loss: {loss.item():.4f}')\n",
        "\n",
        "student_end_time = time.time()  # 평가 시작 시간 기록\n",
        "student_learning_time = student_end_time - student_start_time  # 소요 시간 계산\n",
        "print(f'Learning Time: {student_learning_time:.4f} seconds')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZFSznFnSu81",
        "outputId": "c8b8e3d4-572d-4e3c-bd37-c9f68686a3e7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2976: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Loss: 0.3004\n",
            "Epoch [2/5], Loss: 0.2195\n",
            "Epoch [3/5], Loss: 0.1888\n",
            "Epoch [4/5], Loss: 0.2291\n",
            "Epoch [5/5], Loss: 0.2002\n",
            "Learning Time: 72.3704 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "0zhHmAgreEgJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 평가 함수\n",
        "def evaluate_model(model, test_loader):\n",
        "    model.eval()  # 평가 모드로 전환\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    start_time = time.time()  # 평가 시작 시간 기록\n",
        "\n",
        "    with torch.no_grad():  # 그래디언트 계산 비활성화\n",
        "        for images, labels in test_loader:\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    end_time = time.time()  # 평가 종료 시간 기록\n",
        "    accuracy = correct / total\n",
        "    evaluation_time = end_time - start_time  # 소요 시간 계산\n",
        "    return accuracy, evaluation_time\n",
        "\n",
        "# Teacher 모델 성능 평가\n",
        "teacher_accuracy, teacher_time = evaluate_model(teacher_model, test_loader)\n",
        "print('# Teacher')\n",
        "print(f'Learning Time: {teacher_learning_time:.4f} seconds')\n",
        "print(f'Test Accuracy: {teacher_accuracy * 100:.2f}%')\n",
        "print(f'Inference Time: {teacher_time:.4f} seconds')\n",
        "\n",
        "# Student 모델 성능 평가\n",
        "student_accuracy, student_time = evaluate_model(student_model, test_loader)\n",
        "print('# Student')\n",
        "print(f'Learning Time: {student_learning_time:.4f} seconds')\n",
        "print(f'Test Accuracy: {student_accuracy * 100:.2f}%')\n",
        "print(f'Inference Time: {student_time:.4f} seconds')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WgzRTFPDeEl9",
        "outputId": "d163fb54-d3c1-483f-ea26-5c70e18734a3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Teacher\n",
            "Learning Time: 94.4465 seconds\n",
            "Test Accuracy: 95.85%\n",
            "Inference Time: 2.0006 seconds\n",
            "# Student\n",
            "Learning Time: 72.3704 seconds\n",
            "Test Accuracy: 96.13%\n",
            "Inference Time: 1.9377 seconds\n"
          ]
        }
      ]
    }
  ]
}