https://velog.io/@ahn_kyuwon/%EA%B8%B0%EC%88%A0-Instruction-tuning

## [Instruction tuning]

`instruct` : 지시하다/설명하다/가르치다

`Fine tuning`과 `Prompt Engineering`의 장점을 결합해 `다양한 종류의 Task가 instruction 형태로 적재된 데이터셋`을 활용해 모델의 유연성과 정확성을 향상시키기 위한 전략

>Instruction 데이터셋 `샘플`을 만든 후 LLM (GPT-3 모델) 에게 해당 샘플과 동일한 구조를 갖도록 데이터셋을 만들도록 하여 데이터셋 생성에 대한 시간과 노력을 대폭 축소할 수도 있다~! 한마디로 데이터셋도 LLM이 생성하게 하는 것 (self -instruction)

## [Zero-Shot]

`모델이 학습 과정에서 배우지 않은 작업을 수행하는 것`을 의미한다. Vision에서는 새로운 클래스가 되겠고, NLP에서는 새로운 유형의 `task`가 되겠다. 예시 없이 바로 대답이 가능한 경우.

+ 유인나의 목소리로 음성을 생성하도록 학습한 TTS 모델이 예시 샘플을 이용하여 아이유의 목소리로도 음성을 생성하는 것
+ 셰익스피어처럼 글을 쓰도록 학습한 자연어 생성 모델이 마크 트웨인의 스타일로 글을 쓰는 것
+ 학습 과정에서 존재하지 않았던 종류의 이미지를 생성하는 것

음성 모델이 음성을 구성하는 성분들을 이해하도록 하고, 자연어 모델이 언어 자체를 이해하고, 이미지 모델이 이미지 자체를 이해하도록 하는 것


## [Few-Shot]

Zero shot과 유사하다. `매우 제한된 양의 학습 데이터만을 사용하여 새로운 작업을 수행할 수 있게 하는 rjt`것을 의미한다. 모델에 몇 가지의 `few prompts`를 제공한다.

+ One-shot
```
Prompt 
 "그 영화는 너무 지루해" -> 부정적 
 "그 영화 심심했어" -> 
GPT
 부정적
``` 

+ Few-shot
```
Prompt : 
"그 영화는 너무 지루해" -> 부정적 
"그 영화 뭐 그냥 볼만해" -> 중립적
"그 영화 정말 재미 있던데?" -> 긍정적
"그 영화 신나" ->
GPT 
 긍정적
 ```

## [In-Context Learning]

`context` 내에서 필요한 정보를 바탕으로 학습하는 방식이다. 기존의 대규모 데이터 세트를 통해 `pre-training`하는 과정 없이, 제한된 정보 내에서 바로 학습하고 적용할 수 있는 방식으로 소규모 데이터를 가진 연구자나 개발자도 AI 모델을 훈련시킬 수 있다.

예시마다 가중치가 업데이트 되던 기존 방식과 다르기 때문에 Prompt에 대한 중요성 또한 대두되었다. 하지만 해당 방식의 한계점 또한 존재하는데, 바로 여러 스텝을 거쳐야 풀 수 있는 문제들과 같이 Prompt만으로 배우기 어려운 문제들이다.

## [Chain-of-Thought]

해결 방식을 `step by step`으로 제시함으로써 모델의 Prompt 이해도를 높인다.
모델의 크기가 클 때 Chain-of-thought를 적용하면 지도학습 성능을 따라가는 양상을 보여줌


## [Zero-shot COT prompting]

기존의 step by step 제시를 LLM inference 결과로 대체

>쉽게 말해서, 파라미터 값을 바꾸지 않고 쿼리를 잘 만들어서 원하는 출력을 만들어 보자는 편한 접근법이다.

이미 많은 지식과 언어적인 능력을 가지고 있는 상태이므로, 이들을 연결 시킬 가이드만 제시하면 그 가이드를 참고해서 새로운 상황이나 질문에 답할 수 있다는 것.

## [Fine Tuning]

특정 도메인이나 task에 대해서는 파인튜닝 기법이 더 효과적이다. 특히나 내재된 정보가 적을수록`(작은 모델일수록)`

원하는 형식을 모델이 배운 상태이므로 별도의 프롬프트 설계 없이 `Zero-shot` 만으로도 한번에 원하는 출력을 만들 수 있다. 그만큼 단점도 뚜렷하다.

- 특정 task에 대한 데이터셋이 필요합니다. 이러한 데이터를 수집하고 레이블링하는 작업은 시간과 비용이 많이 소요됨.

- 특정 Task에만 최적화되어 있어 유형이 달라지면 대응이 잘 되지 않고 유연성이 떨어짐

사실 이런 단점은 In-Context learning의 장점이 되기도 하는데, 모델 업데이트가 아닌 프롬프트 조작만으로 가능하기 때문에 범용성이나 유연성 면에서는 파인튜닝 보다 유리하다.
