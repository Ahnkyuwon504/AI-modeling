####################################
## 필요한 것
####################################
# AWS 계정
# huggingface token id(READ)
# https://huggingface.co/google/gemma-2-2b-it 모델에 대한 권한

####################################
## 인스턴스 시작
####################################
# 패키지 리스트 업데이트
$ sudo apt-get update

# 필수 패키지 설치
$ sudo apt-get install \
	apt-transport-https \
    ca-certificates \
    curl \
    gnupg \
    lsb-release \
    software-properties-common

####################################
## docker 설치
####################################    
# GPG key 추가
$ sudo curl -fsSL https://download.docker.com/linux/ubuntu/gpg -o /etc/apt/keyrings/docker.asc

# docker 저장소 설정
$ echo "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/ubuntu $(. /etc/os-release && echo "$VERSION_CODENAME") stable" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null

# 패키지 리스트 다시 업데이트
$ sudo apt-get update

# docker 설치
$ sudo apt-get install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin

# 현재 사용자를 docker그룹에 추가
$ sudo usermod -aG docker $USER

# 도커세션 새로고침
$ newgrp docker

# 확인
$ docker run hello-world

####################################
## git 설치
####################################
$ sudo apt install git

# 확인
$ git --version

# ssh키 추가
$ ssh-keygen -t rsa -b 2048 -f ~/.ssh/test_key

# config
$ vi ~/.ssh/config

# config
Host github.com
     HostName github.com
     User git
     IdentityFile ~/.ssh/test_key
     IdentitiesOnly yes
     Port 22

# git clone

####################################
## python 설치
####################################
# Python 3 설치
$ sudo apt install python3

# 확인
$ python3 --version

# pip 설치
$ sudo apt install python3-pip

# 가상환경 설치
$ sudo apt install python3-venv

# 가상환경 생성
$ python3 -m venv kyuenv

####################################
## llama.cpp 설치
####################################
$ git clone https://github.com/ggerganov/llama.cpp
$ cd llama.cpp

# 빌드
$ make -j

####################################
## CPU 기반 추론
####################################

####################################
## 환경변수 설정
####################################
$ echo 'export HF_TOKEN="{token id}"' >> ~/.bashrc
$ source ~/.bashrc

####################################
## 필요 패키지 설치
####################################
$ source kyuenv/bin/activate
$ pip install -r requirements.txt

####################################
## 모델 다운로드
####################################
$ python3 download.py

####################################
## 모델 변환(safetensors -> bf16 gguf)
####################################
$ sh convert.sh

# gguf제외하고 전부 삭제
$ find . -type f ! -name '*.gguf' -delete

####################################
## 양자화(bf16 gguf -> 5bit)
####################################
$ sh quantize.sh

####################################
## 추론(16비트/5비트)
####################################
$ sh llama.cpp.gguf.infer.sh

# gemma2 16bit 기준 약 60초
# gemma2 5bit 기준 약 35초

####################################
## GPU 기반 추론
####################################

####################################
## NVIDIA 드라이버 설치
####################################
# GPU 확인
$ lspci | grep -i nvidia

# 커널/os 확인
$ uname -a && cat /etc/os-release

# NVIDIA 드라이버 설치
$ sudo apt install -y ubuntu-drivers-common
$ sudo ubuntu-drivers install

# 재부팅
$ sudo reboot

# 확인
$ nvidia-smi

####################################
## cuda toolkit 설치
####################################
$ sudo apt install nvidia-cuda-toolkit

# 확인
$ nvcc --version

# 현시점에서 추론시 GPU메모리에 로드되지 않음

####################################
## llama.cpp 재빌드
####################################
# GPU index 환경변수로 추가. 사실 단일GPU면 안해도 됨
$ export CUDA_VISIBLE_DEVICES=0 >> ~/.bashrc
$ source ~/.bashrc

# 종전에 make로 빌드했기 때문에, CPU기반 실행파일 제거
$ make clean

# GPU사용하도록 재빌드
$ make GGML_CUDA=1 -j

# 재추론. GPU메모리에 로딩됨을 확인
# --n-gpu-layers 옵션을 지정해 GPU에 오프로딩할 레이어를 최적화해야함
$ sh llama.cpp.gguf.infer.sh

# BF16: 큰 차이 없음(--n-gpu-layers:1)
# Q5_K_S: 1분 -> 3초(--n-gpu-layers:60)

####################################
## docker 컨테이너 구동
####################################
$ sh run.docker.sh

####################################
## nvidia-container-toolkit 설치
####################################
# GPG키 추가/레포지토리 설정
$ curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg \
  && curl -s -L https://nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list | \
    sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | \
    sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list

# update
$ sudo apt-get update

# 다운로드
$ sudo apt-get install -y nvidia-container-toolkit

# docker데몬 재시작
$ sudo systemctl restart docker

####################################
## 컨테이너 재기동
####################################
$ sh run.docker.sh

# http 요청
$ sh container.query.sh

####################################
## 웹서버 컨테이너
####################################
$ docker build -t gradio-app .

$ docker images

$ docker run --rm -d -p 7860:7860 gradio-app

####################################
## 
####################################

####################################
## 
####################################

####################################
## 
####################################

####################################
## 
####################################

####################################
## 
####################################

####################################
## TODO
####################################
# historical/multi-turn
# token streaming